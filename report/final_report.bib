@misc{abnarQuantifyingAttentionFlow2020,
  title = {Quantifying {{Attention Flow}} in {{Transformers}}},
  author = {Abnar, Samira and Zuidema, Willem},
  year = {2020},
  month = may,
  number = {arXiv:2005.00928},
  eprint = {2005.00928},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {In the Transformer model, "self-attention" combines information from attended embeddings into the representation of the focal embedding in the next layer. Thus, across layers of the Transformer, information originating from different tokens gets increasingly mixed. This makes attention weights unreliable as explanations probes. In this paper, we consider the problem of quantifying this flow of information through self-attention. We propose two methods for approximating the attention to input tokens given attention weights, attention rollout and attention flow, as post hoc methods when we use attention weights as the relative relevance of the input tokens. We show that these methods give complementary views on the flow of information, and compared to raw attention, both yield higher correlations with importance scores of input tokens obtained using an ablation method and input gradients.},
  archiveprefix = {arXiv}
}

@article{aljanahiIntroductionAnalysisSingleCell2018,
  title = {An {{Introduction}} to the {{Analysis}} of {{Single-Cell RNA-Sequencing Data}}},
  author = {AlJanahi, Aisha A. and Danielsen, Mark and Dunbar, Cynthia E.},
  year = {2018},
  month = sep,
  journal = {Molecular Therapy. Methods \& Clinical Development},
  volume = {10},
  pages = {189--196},
  issn = {2329-0501},
  doi = {10.1016/j.omtm.2018.07.003},
  abstract = {The recent development of single-cell RNA sequencing has deepened our understanding of the cell as a functional unit, providing new insights based on gene expression profiles of hundreds to hundreds of thousands of individual cells, and revealing new populations of cells with distinct gene expression profiles previously hidden within analyses of gene expression performed on bulk cell populations. However, appropriate analysis and utilization of the massive amounts of data generated from single-cell RNA sequencing experiments are challenging and require an understanding of the experimental and computational pathways taken between preparation of input cells and output of interpretable data. In this review, we will discuss the basic principles of these new technologies, focusing on concepts important in the analysis of single-cell RNA-sequencing data. Specifically, we summarize approaches to quality-control measures for determination of which single cells to include for further examination, methods of data normalization and scaling to overcome the relatively inefficient capture rate of mRNA from each cell, and clustering and visualization algorithms used for dimensional reduction of the data to a two-dimensional plot.},
  langid = {english},
  pmcid = {PMC6072887},
  pmid = {30094294}
}

@article{briggsSinglecellTranscriptomicAnalysis2021,
  title = {Single-Cell Transcriptomic Analysis of Bloodstream {{Trypanosoma}} Brucei Reconstructs Cell Cycle Progression and Developmental Quorum Sensing},
  author = {Briggs, Emma M. and Rojas, Federico and McCulloch, Richard and Matthews, Keith R. and Otto, Thomas D.},
  year = {2021},
  month = sep,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {5268},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-25607-2},
  abstract = {Developmental steps in the trypanosome life-cycle involve transition between replicative and non-replicative forms specialised for survival in, and transmission between, mammalian and tsetse fly hosts. Here, using oligopeptide-induced differentiation in vitro, we model the progressive development of replicative 'slender' to transmissible 'stumpy' bloodstream form Trypanosoma brucei and capture the transcriptomes of 8,599 parasites using single cell transcriptomics (scRNA-seq). Using this framework, we detail the relative order of biological events during asynchronous development, profile dynamic gene expression patterns and identify putative regulators. We additionally map the cell~cycle of proliferating parasites and position stumpy cell-cycle exit at early G1 before progression to a distinct G0 state. A null mutant for one transiently elevated developmental regulator, ZC3H20 is further analysed by scRNA-seq, identifying its point of failure in the developmental atlas. This approach provides a paradigm for the dissection of differentiation events in parasites, relevant to diverse transitions in pathogen biology.},
  langid = {english},
  pmcid = {PMC8421343},
  pmid = {34489460}
}

@article{chenTransformerOneStop2023,
  title = {Transformer for One Stop Interpretable Cell Type Annotation},
  author = {Chen, Jiawei and Xu, Hao and Tao, Wanyu and Chen, Zhaoxiong and Zhao, Yuxuan and Han, Jing-Dong J.},
  year = {2023},
  month = jan,
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {223},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-35923-4},
  abstract = {Consistent annotation transfer from reference dataset to query dataset is fundamental to the development and reproducibility of single-cell research. Compared with traditional annotation methods, deep learning based methods are faster and more automated. A series of useful single cell analysis tools based on autoencoder architecture have been developed but these struggle to strike a balance between depth and interpretability. Here, we present TOSICA, a multi-head self-attention deep learning model based on Transformer that enables interpretable cell type annotation using biologically understandable entities, such as pathways or regulons. We show that TOSICA achieves fast and accurate one-stop annotation and batch-insensitive integration while providing biologically interpretable insights for understanding cellular behavior during development and disease progressions. We demonstrate TOSICA’s advantages by applying it to scRNA-seq data of tumor-infiltrating immune cells, and CD14+ monocytes in COVID-19 to reveal rare cell types, heterogeneity and dynamic trajectories associated with disease progression and severity.},
  copyright = {2023 The Author(s)},
  langid = {english}
}

@misc{childGeneratingLongSequences2019,
  title = {Generating {{Long Sequences}} with {{Sparse Transformers}}},
  author = {Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  year = {2019},
  month = apr,
  number = {arXiv:1904.10509},
  eprint = {1904.10509},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1904.10509},
  abstract = {Transformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to \$O(n \textbackslash sqrt\{n\})\$. We also introduce a) a variation on architecture and initialization to train deeper networks, b) the recomputation of attention matrices to save memory, and c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, CIFAR-10, and ImageNet-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more.},
  archiveprefix = {arXiv}
}

@misc{choromanskiRethinkingAttentionPerformers2022,
  title = {Rethinking {{Attention}} with {{Performers}}},
  author = {Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and Belanger, David and Colwell, Lucy and Weller, Adrian},
  year = {2022},
  month = nov,
  number = {arXiv:2009.14794},
  eprint = {2009.14794},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2009.14794},
  abstract = {We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can be also used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers.},
  archiveprefix = {arXiv}
}

@article{crickCentralDogmaMolecular1970,
  title = {Central Dogma of Molecular Biology},
  author = {Crick, F.},
  year = {1970},
  month = aug,
  journal = {Nature},
  volume = {227},
  number = {5258},
  pages = {561--563},
  issn = {0028-0836},
  doi = {10.1038/227561a0},
  langid = {english},
  pmid = {4913914}
}

@misc{cuiScFormerUniversalRepresentation2022,
  title = {{{scFormer}}: {{A Universal Representation Learning Approach}} for {{Single-Cell Data Using Transformers}}},
  shorttitle = {{{scFormer}}},
  author = {Cui, Haotian and Wang, Chloe and Maan, Hassaan and Duan, Nan and Wang, Bo},
  year = {2022},
  month = nov,
  pages = {2022.11.20.517285},
  publisher = {{bioRxiv}},
  doi = {10.1101/2022.11.20.517285},
  abstract = {Single-cell sequencing has emerged as a promising technique to decode cellular heterogeneity and analyze gene functions. With the high throughput of modern techniques and resulting large-scale sequencing data, deep learning has been used extensively to learn representations of individual cells for downstream tasks. However, most existing methods rely on fully connected networks and are unable to model complex relationships between both cell and gene representations. We hereby propose scFormer, a novel transformer-based deep learning framework to jointly optimize cell and gene embeddings for single-cell biology in an unsupervised manner. By drawing parallels between natural language processing and genomics, scFormer applies self-attention to learn salient gene and cell embeddings through masked gene modelling. scFormer provides a unified framework to readily address a variety of downstream tasks such as data integration, analysis of gene function, and perturbation response prediction. Extensive experiments using scFormer show state-of-the-art performance on seven datasets across the relevant tasks. The scFormer model implementation is available at https://github.com/bowang-lab/scFormer.},
  chapter = {New Results},
  copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english}
}

@misc{daiTransformerXLAttentiveLanguage2019,
  title = {Transformer-{{XL}}: {{Attentive Language Models Beyond}} a {{Fixed-Length Context}}},
  shorttitle = {Transformer-{{XL}}},
  author = {Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V. and Salakhutdinov, Ruslan},
  year = {2019},
  month = jun,
  number = {arXiv:1901.02860},
  eprint = {1901.02860},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1901.02860},
  abstract = {Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80\% longer than RNNs and 450\% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.},
  archiveprefix = {arXiv}
}

@misc{DeepLearningTackles,
  title = {Deep Learning Tackles Single-Cell Analysis—a Survey of Deep Learning for {{scRNA-seq}} Analysis | {{Briefings}} in {{Bioinformatics}} | {{Oxford Academic}}},
  howpublished = {https://academic.oup.com/bib/article/23/1/bbab531/6470968?login=true}
}

@article{farrellSinglecellReconstructionDevelopmental2018,
  title = {Single-Cell Reconstruction of Developmental Trajectories during Zebrafish Embryogenesis},
  author = {Farrell, Jeffrey A. and Wang, Yiqun and Riesenfeld, Samantha J. and Shekhar, Karthik and Regev, Aviv and Schier, Alexander F.},
  year = {2018},
  month = jun,
  journal = {Science},
  volume = {360},
  number = {6392},
  pages = {eaar3131},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aar3131},
  abstract = {During embryogenesis, cells acquire distinct fates by transitioning through transcriptional states. To uncover these transcriptional trajectories during zebrafish embryogenesis, we sequenced 38,731 cells and developed URD, a simulated diffusion-based computational reconstruction method. URD identified the trajectories of 25 cell types through early somitogenesis, gene expression along them, and their spatial origin in the blastula. Analysis of Nodal signaling mutants revealed that their transcriptomes were canalized into a subset of wild-type transcriptional trajectories. Some wild-type developmental branch points contained cells that express genes characteristic of multiple fates. These cells appeared to trans-specify from one fate to another. These findings reconstruct the transcriptional trajectories of a vertebrate embryo, highlight the concurrent canalization and plasticity of embryonic specification, and provide a framework with which to reconstruct complex developmental trees from single-cell transcriptomes.}
}

@article{floresDeepLearningTackles2022,
  title = {Deep Learning Tackles Single-Cell Analysis-a Survey of Deep Learning for {{scRNA-seq}} Analysis},
  author = {Flores, Mario and Liu, Zhentao and Zhang, Tinghe and Hasib, Md Musaddaqui and Chiu, Yu-Chiao and Ye, Zhenqing and Paniagua, Karla and Jo, Sumin and Zhang, Jianqiu and Gao, Shou-Jiang and Jin, Yu-Fang and Chen, Yidong and Huang, Yufei},
  year = {2022},
  month = jan,
  journal = {Briefings in Bioinformatics},
  volume = {23},
  number = {1},
  pages = {bbab531},
  issn = {1477-4054},
  doi = {10.1093/bib/bbab531},
  abstract = {Since its selection as the method of the year in 2013, single-cell technologies have become mature enough to provide answers to complex research questions. With the growth of single-cell profiling technologies, there has also been a significant increase in data collected from single-cell profilings, resulting in computational challenges to process these massive and complicated datasets. To address these challenges, deep learning (DL) is positioned as a competitive alternative for single-cell analyses besides the traditional machine learning approaches. Here, we survey a total of 25 DL algorithms and their applicability for a specific step in the single cell RNA-seq processing pipeline. Specifically, we establish a unified mathematical representation of variational autoencoder, autoencoder, generative adversarial network and supervised DL models, compare the training strategies and loss functions for these models, and relate the loss functions of these models to specific objectives of the data processing step. Such a presentation will allow readers to choose suitable algorithms for their particular objective at each step in the pipeline. We envision that this survey will serve as an important information portal for learning the application of DL for scRNA-seq analysis and inspire innovative uses of DL to address a broader range of new challenges in emerging multi-omics and spatial single-cell sequencing.},
  langid = {english},
  pmcid = {PMC8769926},
  pmid = {34929734}
}

@article{floresDeepLearningTackles2022a,
  title = {Deep Learning Tackles Single-Cell Analysis—a Survey of Deep Learning for {{scRNA-seq}} Analysis},
  author = {Flores, Mario and Liu, Zhentao and Zhang, Tinghe and Hasib, Md Musaddaqui and Chiu, Yu-Chiao and Ye, Zhenqing and Paniagua, Karla and Jo, Sumin and Zhang, Jianqiu and Gao, Shou-Jiang and Jin, Yu-Fang and Chen, Yidong and Huang, Yufei},
  year = {2022},
  month = jan,
  journal = {Briefings in Bioinformatics},
  volume = {23},
  number = {1},
  pages = {bbab531},
  issn = {1467-5463, 1477-4054},
  doi = {10.1093/bib/bbab531},
  abstract = {Since its selection as the method of the year in 2013, single-cell technologies have become mature enough to provide answers to complex research questions. With the growth of single-cell profiling technologies, there has also been a significant increase in data collected from single-cell profilings, resulting in computational challenges to process these massive and complicated datasets. To address these challenges, deep learning (DL) is positioned as a competitive alternative for single-cell analyses besides the traditional machine learning approaches. Here, we survey a total of 25 DL algorithms and their applicability for a specific step in the single cell RNA-seq processing pipeline. Specifically, we establish a unified mathematical representation of variational autoencoder, autoencoder, generative adversarial network and supervised DL models, compare the training strategies and loss functions for these models, and relate the loss functions of these models to specific objectives of the data processing step. Such a presentation will allow readers to choose suitable algorithms for their particular objective at each step in the pipeline. We envision that this survey will serve as an important information portal for learning the application of DL for scRNA-seq analysis and inspire innovative uses of DL to address a broader range of new challenges in emerging multi-omics and spatial single-cell sequencing.},
  langid = {english}
}

@article{floresDeepLearningTackles2022b,
  title = {Deep Learning Tackles Single-Cell Analysis—a Survey of Deep Learning for {{scRNA-seq}} Analysis},
  author = {Flores, Mario and Liu, Zhentao and Zhang, Tinghe and Hasib, Md Musaddaqui and Chiu, Yu-Chiao and Ye, Zhenqing and Paniagua, Karla and Jo, Sumin and Zhang, Jianqiu and Gao, Shou-Jiang and Jin, Yu-Fang and Chen, Yidong and Huang, Yufei},
  year = {2022},
  month = jan,
  journal = {Briefings in Bioinformatics},
  volume = {23},
  number = {1},
  pages = {bbab531},
  issn = {1467-5463, 1477-4054},
  doi = {10.1093/bib/bbab531},
  abstract = {Since its selection as the method of the year in 2013, single-cell technologies have become mature enough to provide answers to complex research questions. With the growth of single-cell profiling technologies, there has also been a significant increase in data collected from single-cell profilings, resulting in computational challenges to process these massive and complicated datasets. To address these challenges, deep learning (DL) is positioned as a competitive alternative for single-cell analyses besides the traditional machine learning approaches. Here, we survey a total of 25 DL algorithms and their applicability for a specific step in the single cell RNA-seq processing pipeline. Specifically, we establish a unified mathematical representation of variational autoencoder, autoencoder, generative adversarial network and supervised DL models, compare the training strategies and loss functions for these models, and relate the loss functions of these models to specific objectives of the data processing step. Such a presentation will allow readers to choose suitable algorithms for their particular objective at each step in the pipeline. We envision that this survey will serve as an important information portal for learning the application of DL for scRNA-seq analysis and inspire innovative uses of DL to address a broader range of new challenges in emerging multi-omics and spatial single-cell sequencing.},
  langid = {english}
}

@misc{grattarolaGraphNeuralNetworks2020,
  title = {Graph {{Neural Networks}} in {{TensorFlow}} and {{Keras}} with {{Spektral}}},
  author = {Grattarola, Daniele and Alippi, Cesare},
  year = {2020},
  month = jun,
  number = {arXiv:2006.12138},
  eprint = {2006.12138},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.12138},
  abstract = {In this paper we present Spektral, an open-source Python library for building graph neural networks with TensorFlow and the Keras application programming interface. Spektral implements a large set of methods for deep learning on graphs, including message-passing and pooling operators, as well as utilities for processing graphs and loading popular benchmark datasets. The purpose of this library is to provide the essential building blocks for creating graph neural networks, focusing on the guiding principles of user-friendliness and quick prototyping on which Keras is based. Spektral is, therefore, suitable for absolute beginners and expert deep learning practitioners alike. In this work, we present an overview of Spektral's features and report the performance of the methods implemented by the library in scenarios of node classification, graph classification, and graph regression.},
  archiveprefix = {arXiv}
}

@misc{hansenTENxPBMCData2018,
  title = {{{TENxPBMCData}}},
  author = {Hansen, Kasper and Risso, Davide and Hicks, Stephanie},
  year = {2018},
  doi = {10.18129/B9.BIOC.TENXPBMCDATA},
  collaborator = {Malfait, Milan and Gillis, Jeroen and Killian, Theodore and Kose, Murat and Tang, Chong and {van den Brand}, Teun and Machlab, Dania},
  howpublished = {Bioconductor}
}

@article{harrisArrayProgrammingNumPy2020,
  title = {Array Programming with {{NumPy}}},
  author = {Harris, Charles R. and Millman, K. Jarrod and {van der Walt}, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and {van Kerkwijk}, Marten H. and Brett, Matthew and Haldane, Allan and {del Río}, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and {Gérard-Marchant}, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
  year = {2020},
  month = sep,
  journal = {Nature},
  volume = {585},
  number = {7825},
  pages = {357--362},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2649-2},
  abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
  copyright = {2020 The Author(s)},
  langid = {english}
}

@article{heumosBestPracticesSinglecell2023,
  title = {Best Practices for Single-Cell Analysis across Modalities},
  author = {Heumos, Lukas and Schaar, Anna C. and Lance, Christopher and Litinetskaya, Anastasia and Drost, Felix and Zappia, Luke and Lücken, Malte D. and Strobl, Daniel C. and Henao, Juan and Curion, Fabiola and Schiller, Herbert B. and Theis, Fabian J.},
  year = {2023},
  month = aug,
  journal = {Nature Reviews Genetics},
  volume = {24},
  number = {8},
  pages = {550--572},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/s41576-023-00586-w},
  abstract = {Recent advances in single-cell technologies have enabled high-throughput molecular profiling of cells across modalities and locations. Single-cell transcriptomics data can now be complemented by chromatin accessibility, surface protein expression, adaptive immune receptor repertoire profiling and spatial information. The increasing availability of single-cell data across modalities has motivated the development of novel computational methods to help analysts derive biological insights. As the field grows, it becomes increasingly difficult to navigate the vast landscape of tools and analysis steps. Here, we summarize independent benchmarking studies of unimodal and multimodal single-cell analysis across modalities to suggest comprehensive best-practice workflows for the most common analysis steps. Where independent benchmarks are not available, we review and contrast popular methods. Our article serves as an entry point for novices in the field of single-cell (multi-)omic analysis and guides advanced users to the most recent best practices.},
  copyright = {2023 Springer Nature Limited},
  langid = {english}
}

@article{howickMalariaCellAtlas2019,
  title = {The {{Malaria Cell Atlas}}: {{Single}} Parasite Transcriptomes across the Complete {{Plasmodium}} Life Cycle},
  shorttitle = {The {{Malaria Cell Atlas}}},
  author = {Howick, Virginia M. and Russell, Andrew J. C. and Andrews, Tallulah and Heaton, Haynes and Reid, Adam J. and Natarajan, Kedar and Butungi, Hellen and Metcalf, Tom and Verzier, Lisa H. and Rayner, Julian C. and Berriman, Matthew and Herren, Jeremy K. and Billker, Oliver and Hemberg, Martin and Talman, Arthur M. and Lawniczak, Mara K. N.},
  year = {2019},
  month = aug,
  journal = {Science},
  volume = {365},
  number = {6455},
  pages = {eaaw2619},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aaw2619},
  abstract = {Malaria parasites adopt a remarkable variety of morphological life stages as they transition through multiple mammalian host and mosquito vector environments. We profiled the single-cell transcriptomes of thousands of individual parasites, deriving the first high-resolution transcriptional atlas of the entire Plasmodium berghei life cycle. We then used our atlas to precisely define developmental stages of single cells from three different human malaria parasite species, including parasites isolated directly from infected individuals. The Malaria Cell Atlas provides both a comprehensive view of gene usage in a eukaryotic parasite and an open-access reference dataset for the study of malaria parasites.}
}

@article{hunterMatplotlib2DGraphics2007,
  title = {Matplotlib: {{A 2D Graphics Environment}}},
  shorttitle = {Matplotlib},
  author = {Hunter, John D.},
  year = {2007},
  journal = {Computing in Science \& Engineering},
  volume = {9},
  number = {3},
  pages = {90--95},
  issn = {1521-9615},
  doi = {10.1109/MCSE.2007.55}
}

@misc{katharopoulosTransformersAreRNNs2020,
  title = {Transformers Are {{RNNs}}: {{Fast Autoregressive Transformers}} with {{Linear Attention}}},
  shorttitle = {Transformers Are {{RNNs}}},
  author = {Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, François},
  year = {2020},
  month = aug,
  number = {arXiv:2006.16236},
  eprint = {2006.16236},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.16236},
  abstract = {Transformers achieve remarkable performance in several tasks but due to their quadratic complexity, with respect to the input's length, they are prohibitively slow for very long sequences. To address this limitation, we express the self-attention as a linear dot-product of kernel feature maps and make use of the associativity property of matrix products to reduce the complexity from \$\textbackslash mathcal\{O\}\textbackslash left(N\^2\textbackslash right)\$ to \$\textbackslash mathcal\{O\}\textbackslash left(N\textbackslash right)\$, where \$N\$ is the sequence length. We show that this formulation permits an iterative implementation that dramatically accelerates autoregressive transformers and reveals their relationship to recurrent neural networks. Our linear transformers achieve similar performance to vanilla transformers and they are up to 4000x faster on autoregressive prediction of very long sequences.},
  archiveprefix = {arXiv}
}

@misc{kipfSemiSupervisedClassificationGraph2017,
  title = {Semi-{{Supervised Classification}} with {{Graph Convolutional Networks}}},
  author = {Kipf, Thomas N. and Welling, Max},
  year = {2017},
  month = feb,
  number = {arXiv:1609.02907},
  eprint = {1609.02907},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1609.02907},
  abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
  archiveprefix = {arXiv}
}

@misc{kitaevReformerEfficientTransformer2020,
  title = {Reformer: {{The Efficient Transformer}}},
  shorttitle = {Reformer},
  author = {Kitaev, Nikita and Kaiser, Łukasz and Levskaya, Anselm},
  year = {2020},
  month = feb,
  number = {arXiv:2001.04451},
  eprint = {2001.04451},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2001.04451},
  abstract = {Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(\$L\^2\$) to O(\$L\textbackslash log L\$), where \$L\$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of \$N\$ times, where \$N\$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.},
  archiveprefix = {arXiv}
}

@article{lawlorSinglecellTranscriptomesIdentify2017,
  title = {Single-Cell Transcriptomes Identify Human Islet Cell Signatures and Reveal Cell-Type–Specific Expression Changes in Type 2 Diabetes},
  author = {Lawlor, Nathan and George, Joshy and Bolisetty, Mohan and Kursawe, Romy and Sun, Lili and Sivakamasundari, V. and Kycia, Ina and Robson, Paul and Stitzel, Michael L.},
  year = {2017},
  month = feb,
  journal = {Genome Research},
  volume = {27},
  number = {2},
  pages = {208--222},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.212720.116},
  abstract = {Blood glucose levels are tightly controlled by the coordinated action of at least four cell types constituting pancreatic islets. Changes in the proportion and/or function of these cells are associated with genetic and molecular pathophysiology of monogenic, type 1, and type 2 (T2D) diabetes. Cellular heterogeneity impedes precise understanding of the molecular components of each islet cell type that govern islet (dys)function, particularly the less abundant delta and gamma/pancreatic polypeptide (PP) cells. Here, we report single-cell transcriptomes for 638 cells from nondiabetic (ND) and T2D human islet samples. Analyses of ND single-cell transcriptomes identified distinct alpha, beta, delta, and PP/gamma cell-type signatures. Genes linked to rare and common forms of islet dysfunction and diabetes were expressed in the delta and PP/gamma cell types. Moreover, this study revealed that delta cells specifically express receptors that receive and coordinate systemic cues from the leptin, ghrelin, and dopamine signaling pathways implicating them as integrators of central and peripheral metabolic signals into the pancreatic islet. Finally, single-cell transcriptome profiling revealed genes differentially regulated between T2D and ND alpha, beta, and delta cells that were undetectable in paired whole islet analyses. This study thus identifies fundamental cell-type–specific features of pancreatic islet (dys)function and provides a critical resource for comprehensive understanding of islet biology and diabetes pathogenesis.},
  langid = {english},
  pmid = {27864352}
}

@article{lotfollahiBiologicallyInformedDeep2023,
  title = {Biologically Informed Deep Learning to Query Gene Programs in Single-Cell Atlases},
  author = {Lotfollahi, Mohammad and Rybakov, Sergei and Hrovatin, Karin and {Hediyeh-zadeh}, Soroor and {Talavera-López}, Carlos and Misharin, Alexander V. and Theis, Fabian J.},
  year = {2023},
  month = feb,
  journal = {Nature Cell Biology},
  volume = {25},
  number = {2},
  pages = {337--350},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4679},
  doi = {10.1038/s41556-022-01072-x},
  abstract = {The increasing availability of large-scale single-cell atlases has enabled the detailed description of cell states. In parallel, advances in deep learning allow rapid analysis of newly generated query datasets by mapping them into reference atlases. However, existing data transformations learned to map query data are not easily explainable using biologically known concepts such as genes or pathways. Here we propose expiMap, a biologically informed deep-learning architecture that enables single-cell reference mapping. ExpiMap learns to map cells into biologically understandable components representing known ‘gene programs’. The activity of each cell for a gene program is learned while simultaneously refining them and learning de novo programs. We show that expiMap compares favourably to existing methods while bringing an additional layer of interpretability to integrative single-cell analysis. Furthermore, we demonstrate its applicability to analyse single-cell perturbation responses in different tissues and species and resolve responses of patients who have coronavirus disease 2019 to different treatments across cell types.},
  copyright = {2023 The Author(s)},
  langid = {english}
}

@article{maMultiregionalSinglecellDissection2022,
  title = {Multiregional Single-Cell Dissection of Tumor and Immune Cells Reveals Stable Lock-and-Key Features in Liver Cancer},
  author = {Ma, Lichun and Heinrich, Sophia and Wang, Limin and Keggenhoff, Friederike L. and Khatib, Subreen and Forgues, Marshonna and Kelly, Michael and Hewitt, Stephen M. and Saif, Areeba and Hernandez, Jonathan M. and Mabry, Donna and Kloeckner, Roman and Greten, Tim F. and Chaisaingmongkol, Jittiporn and Ruchirawat, Mathuros and Marquardt, Jens U. and Wang, Xin Wei},
  year = {2022},
  month = dec,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {7533},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-35291-5},
  abstract = {Intratumor heterogeneity may result from the evolution of tumor cells and their continuous interactions with the tumor microenvironment which collectively drives tumorigenesis. However, an appearance of cellular and molecular heterogeneity creates a challenge to define molecular features linked to tumor malignancy. Here we perform multiregional single-cell RNA sequencing (scRNA-seq) analysis of seven liver cancer patients (four hepatocellular carcinoma, HCC and three intrahepatic cholangiocarcinoma, iCCA). We identify cellular dynamics of malignant cells and their communication networks with tumor-associated immune cells, which are validated using additional scRNA-seq data of 25 HCC and 12 iCCA patients as a stable fingerprint embedded in a malignant ecosystem representing features of tumor aggressiveness. We further validate the top ligand-receptor interaction pairs (i.e., LGALS9-SLC1A5 and SPP1-PTGER4 between tumor cells and macrophages) associated with unique transcriptome in additional 542 HCC patients. Our study unveils stable molecular networks of malignant ecosystems, which may open a path for therapeutic exploration.},
  copyright = {2022 This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply},
  langid = {english}
}

@article{maSinglecellAtlasTumor2021,
  title = {Single-Cell Atlas of Tumor Cell Evolution in Response to Therapy in Hepatocellular Carcinoma and Intrahepatic Cholangiocarcinoma},
  author = {Ma, Lichun and Wang, Limin and Khatib, Subreen A. and Chang, Ching-Wen and Heinrich, Sophia and Dominguez, Dana A. and Forgues, Marshonna and Candia, Julián and Hernandez, Maria O. and Kelly, Michael and Zhao, Yongmei and Tran, Bao and Hernandez, Jonathan M. and Davis, Jeremy L. and Kleiner, David E. and Wood, Bradford J. and Greten, Tim F. and Wang, Xin Wei},
  year = {2021},
  month = dec,
  journal = {Journal of Hepatology},
  volume = {75},
  number = {6},
  pages = {1397--1408},
  issn = {0168-8278},
  doi = {10.1016/j.jhep.2021.06.028},
  abstract = {Background \& Aims Intratumor molecular heterogeneity is a key feature of tumorigenesis and is linked to treatment failure and patient prognosis. Herein, we aimed to determine what drives tumor cell evolution by performing single-cell transcriptomic analysis. Methods We analyzed 46 hepatocellular carcinoma (HCC) and intrahepatic cholangiocarcinoma (iCCA) biopsies from 37 patients enrolled in interventional studies at the NIH Clinical Center, with 16 biopsies collected before and after treatment from 7 patients. We developed a novel machine learning-based consensus clustering approach to track cellular states of 57,000 malignant and non-malignant cells including tumor cell transcriptome-based functional clonality analysis. We determined tumor cell relationships using RNA velocity and reverse graph embedding. We also studied longitudinal samples from 4 patients to determine tumor cellular state and its evolution. We validated our findings in bulk transcriptomic data from 488 patients with HCC and 277 patients with iCCA. Results Using transcriptomic clusters as a surrogate for functional clonality, we observed an increase in tumor cell state heterogeneity which was tightly linked to patient prognosis. Furthermore, increased functional clonality was accompanied by a polarized immune cell landscape which included an increase in pre-exhausted T cells. We found that SPP1 expression was tightly associated with tumor cell evolution and microenvironmental reprogramming. Finally, we developed a user-friendly online interface as a knowledge base for a single-cell atlas of liver cancer. Conclusions Our study offers insight into the collective behavior of tumor cell communities in liver cancer as well as potential drivers of tumor evolution in response to therapy. Lay summary Intratumor molecular heterogeneity is a key feature of tumorigenesis that is linked to treatment failure and patient prognosis. In this study, we present a single-cell atlas of liver tumors from patients treated with immunotherapy and describe intratumoral cell states and their hierarchical relationship. We suggest osteopontin, encoded by the gene SPP1, as a candidate regulator of tumor evolution in response to treatment.}
}

@inproceedings{mckinneyDataStructuresStatistical2010,
  title = {Data {{Structures}} for {{Statistical Computing}} in {{Python}}},
  booktitle = {Python in {{Science Conference}}},
  author = {McKinney, Wes},
  year = {2010},
  pages = {56--61},
  address = {{Austin, Texas}},
  doi = {10.25080/Majora-92bf1922-00a}
}

@misc{meritySingleHeadedAttention2019,
  title = {Single {{Headed Attention RNN}}: {{Stop Thinking With Your Head}}},
  shorttitle = {Single {{Headed Attention RNN}}},
  author = {Merity, Stephen},
  year = {2019},
  month = nov,
  number = {arXiv:1911.11423},
  eprint = {1911.11423},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1911.11423},
  abstract = {The leading approaches in language modeling are all obsessed with TV shows of my youth - namely Transformers and Sesame Street. Transformers this, Transformers that, and over here a bonfire worth of GPU-TPU-neuromorphic wafer scale silicon. We opt for the lazy path of old and proven techniques with a fancy crypto inspired acronym: the Single Headed Attention RNN (SHA-RNN). The author's lone goal is to show that the entire field might have evolved a different direction if we had instead been obsessed with a slightly different acronym and slightly different result. We take a previously strong language model based only on boring LSTMs and get it to within a stone's throw of a stone's throw of state-of-the-art byte level language model results on enwik8. This work has undergone no intensive hyperparameter optimization and lived entirely on a commodity desktop machine that made the author's small studio apartment far too warm in the midst of a San Franciscan summer. The final results are achievable in plus or minus 24 hours on a single GPU as the author is impatient. The attention mechanism is also readily extended to large contexts with minimal computation. Take that Sesame Street.},
  archiveprefix = {arXiv}
}

@article{molderSustainableDataAnalysis2021,
  title = {Sustainable Data Analysis with {{Snakemake}}},
  author = {Mölder, Felix and Jablonski, Kim Philipp and Letcher, Brice and Hall, Michael B. and {Tomkins-Tinch}, Christopher H. and Sochat, Vanessa and Forster, Jan and Lee, Soohyun and Twardziok, Sven O. and Kanitz, Alexander and Wilm, Andreas and Holtgrewe, Manuel and Rahmann, Sven and Nahnsen, Sven and Köster, Johannes},
  year = {2021},
  month = apr,
  journal = {F1000Research},
  volume = {10},
  pages = {33},
  issn = {2046-1402},
  doi = {10.12688/f1000research.29032.2},
  abstract = {Data analysis often entails a multitude of heterogeneous steps, from the application of various command line tools to the usage of scripting languages like R or Python for the generation of plots and tables. It is widely recognized that data analyses should ideally be conducted in a reproducible way.~Reproducibility enables technical validation and regeneration of results on the original or even new data. However, reproducibility alone is by no means sufficient to deliver an analysis that is of lasting impact (i.e., sustainable) for the field, or even just one research group. We postulate that it is equally important to ensure adaptability and transparency. The former describes the ability to modify the analysis to answer extended or slightly different research questions. The latter describes the ability to understand the analysis in order to judge whether it is not only technically, but methodologically valid.             Here, we analyze the properties needed for a data analysis to become reproducible, adaptable, and transparent. We show how the popular workflow management system Snakemake can be used to guarantee this, and how it enables an ergonomic, combined, unified representation of all steps involved in data analysis, ranging from raw data processing, to quality control and fine-grained, interactive exploration and plotting of final results.},
  langid = {english}
}

@book{organizationWorldMalariaReport2022,
  title = {World Malaria Report 2022},
  author = {Organization, World Health},
  year = {2022},
  month = dec,
  publisher = {{World Health Organization}},
  abstract = {Each year, WHO’s World malaria report offers in-depth information on the latest trends in malaria control and elimination at global, regional and country levels. The report highlights progress towards global targets and describes opportunities and challenges for curbing and eliminating the disease.This year’s report includes three new sections on: (1) global and regional initiatives launched in 2021 and 2022; (2) global malaria surveillance and country-level case studies on surveillance systems assessments; and (3) research and development. The report also includes an expanded section on threats to malaria control, with a focus on the declining effectiveness of insecticide-treated mosquito nets.},
  isbn = {978-92-4-006489-8},
  langid = {english}
}

@inproceedings{paszkePyTorchImperativeStyle2019,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.}
}

@article{pedregosaScikitlearnMachineLearning2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  shorttitle = {Scikit-Learn},
  author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  number = {85},
  pages = {2825--2830},
  issn = {1533-7928},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.}
}

@article{rezvaniComparativeSinglecellTranscriptional2022,
  title = {Comparative Single-Cell Transcriptional Atlases of {{Babesia}} Species Reveal Conserved and Species-Specific Expression Profiles},
  author = {Rezvani, Yasaman and Keroack, Caroline D. and Elsworth, Brendan and Arriojas, Argenis and Gubbels, Marc-Jan and Duraisingh, Manoj T. and Zarringhalam, Kourosh},
  year = {2022},
  month = sep,
  journal = {PLoS biology},
  volume = {20},
  number = {9},
  pages = {e3001816},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3001816},
  abstract = {Babesia is a genus of apicomplexan parasites that infect red blood cells in vertebrate hosts. Pathology occurs during rapid replication cycles in the asexual blood stage of infection. Current knowledge of Babesia replication cycle progression and regulation is limited and relies mostly on comparative studies with related parasites. Due to limitations in synchronizing Babesia parasites, fine-scale time-course transcriptomic resources are not readily available. Single-cell transcriptomics provides a powerful unbiased alternative for profiling asynchronous cell populations. Here, we applied single-cell RNA sequencing to 3 Babesia species (B. divergens, B. bovis, and B. bigemina). We used analytical approaches and algorithms to map the replication cycle and construct pseudo-synchronized time-course gene expression profiles. We identify clusters of co-expressed genes showing "just-in-time" expression profiles, with gradually cascading peaks throughout asexual development. Moreover, clustering analysis of reconstructed gene curves reveals coordinated timing of peak expression in epigenetic markers and transcription factors. Using a regularized Gaussian graphical model, we reconstructed co-expression networks and identified conserved and species-specific nodes. Motif analysis of a co-expression interactome of AP2 transcription factors identified specific motifs previously reported to play a role in DNA replication in Plasmodium species. Finally, we present an interactive web application to visualize and interactively explore the datasets.},
  langid = {english},
  pmcid = {PMC9531838},
  pmid = {36137068}
}

@misc{rissoScRNAseq2017,
  title = {{{scRNAseq}}},
  author = {Risso, Davide and Cole, Michael},
  year = {2017},
  doi = {10.18129/B9.BIOC.SCRNASEQ},
  collaborator = {Lun, Aaron and O'Callaghan, Alan and Preussner, Jens and Soneson, Charlotte and Orjuela, Stephany and Bunis, Daniel and Malfait, Milan},
  howpublished = {Bioconductor}
}

@article{segundo-valIntroductionGeneExpression2016,
  title = {Introduction to the {{Gene Expression Analysis}}},
  author = {{Segundo-Val}, Ignacio San and {Sanz-Lozano}, Catalina S.},
  year = {2016},
  journal = {Methods in Molecular Biology (Clifton, N.J.)},
  volume = {1434},
  pages = {29--43},
  issn = {1940-6029},
  doi = {10.1007/978-1-4939-3652-6_3},
  abstract = {In 1941, Beadle and Tatum published experiments that would explain the basis of the central dogma of molecular biology, whereby the DNA through an intermediate molecule, called RNA, results proteins that perform the functions in cells. Currently, biomedical research attempts to explain the mechanisms by which develops a particular disease, for this reason, gene expression studies have proven to be a great resource. Strictly, the term "gene expression" comprises from the gene activation until the mature protein is located in its corresponding compartment to perform its function and contribute to the expression of the phenotype of cell.The expression studies are directed to detect and quantify messenger RNA (mRNA) levels of a specific gene. The development of the RNA-based gene expression studies began with the Northern Blot by Alwine et al. in 1977. In 1969, Gall and Pardue and John et al. independently developed the in situ hybridization, but this technique was not employed to detect mRNA until 1986 by Coghlan. Today, many of the techniques for quantification of RNA are deprecated because other new techniques provide more information. Currently the most widely used techniques are qPCR, expression microarrays, and RNAseq for the transcriptome analysis. In this chapter, these techniques will be reviewed.},
  langid = {english},
  pmid = {27300529}
}

@article{shuklaSupervisedLearningPlasmodium2023,
  title = {Supervised Learning of {{Plasmodium}} Falciparum Life Cycle Stages Using Single-Cell Transcriptomes Identifies Crucial Proteins},
  author = {Shukla, Swarnim and Choudhuri, Soham and Priya Iragavarapu, Gayathri and Ghosh, Bhaswar},
  year = {2023},
  journal = {Journal of Bioinformatics and Systems Biology},
  volume = {06},
  number = {01},
  issn = {26885107},
  doi = {10.26502/jbsb.5107047},
  abstract = {Vital gene expressions form the basis for the detection of malaria infection levels. Quantification of infected erythrocytes and classification of their life cycle stages are done at a macroscopic level by experts, for making informed decisions for diagnosis and treatment of malaria. Of late multiple computational approaches have been proposed to circumvent the problem of dimensionality leading to accurately predicted results. In this work, a dimensionality reduction technique based on Genetic Algorithm (GA) is applied to Plasmodium falciparum single cell transcriptomics to arrive at an optimized subset of features from the larger dataset. Features are chosen based on their class variants considering increased efficiency and accuracy, to separately transform the selected elements into a lower dimension. For the classification of the life cycle of malaria parasites based on single cell transcriptome data, a three-pronged approach employing the multiclass Support Vector Machine (SVM), Logistic Regression (LR), and Random Forest (RF) technique is used. Further, we constructed protein interaction networks of the genes identified by the feature selection method and gene ontology analysis elucidated the role of the proteins in the progression of the parasite through its life cycle. Our approach presents a novel protocol to implement ML techniques on scRNA seq datasets and subsequently harness the extracted information for biomarker/drug target detection.},
  langid = {english}
}

@article{speranzaSinglecellRNASequencing2021,
  title = {Single-Cell {{RNA}} Sequencing Reveals {{SARS-CoV-2}} Infection Dynamics in Lungs of {{African}} Green Monkeys},
  author = {Speranza, Emily and Williamson, Brandi N. and Feldmann, Friederike and Sturdevant, Gail L. and {Pérez-Pérez}, Lizzette and {Meade-White}, Kimberly and Smith, Brian J. and Lovaglio, Jamie and Martens, Craig and Munster, Vincent J. and Okumura, Atsushi and Shaia, Carl and Feldmann, Heinz and Best, Sonja M. and {de Wit}, Emmie},
  year = {2021},
  month = jan,
  journal = {Science Translational Medicine},
  volume = {13},
  number = {578},
  pages = {eabe8146},
  issn = {1946-6242},
  doi = {10.1126/scitranslmed.abe8146},
  abstract = {Detailed knowledge about the dynamics of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection is important for uncovering the viral and host factors that contribute to coronavirus disease 2019 (COVID-19) pathogenesis. Old-World nonhuman primates recapitulate mild to moderate cases of COVID-19, thereby serving as important pathogenesis models. We compared African green monkeys inoculated with infectious SARS-CoV-2 or irradiated, inactivated virus to study the dynamics of virus replication throughout the respiratory tract. Genomic RNA from the animals inoculated with the irradiated virus was found to be highly stable, whereas subgenomic RNA, an indicator of viral replication, was found to degrade quickly. We combined this information with single-cell RNA sequencing of cells isolated from the lung and lung-draining mediastinal lymph nodes and developed new analysis methods for unbiased targeting of important cells in the host response to SARS-CoV-2 infection. Through detection of reads to the viral genome, we were able to determine that replication of the virus in the lungs appeared to occur mainly in pneumocytes, whereas macrophages drove the inflammatory response. Monocyte-derived macrophages recruited to the lungs, rather than tissue-resident alveolar macrophages, were most likely to be responsible for phagocytosis of infected cells and cellular debris early in infection, with their roles switching during clearance of infection. Together, our dataset provides a detailed view of the dynamics of virus replication and host responses over the course of mild COVID-19 and serves as a valuable resource to identify therapeutic targets.},
  langid = {english},
  pmcid = {PMC7875333},
  pmid = {33431511}
}

@article{suDenoisingAdaptiveDeep2023,
  title = {Denoising Adaptive Deep Clustering with Self-Attention Mechanism on Single-Cell Sequencing Data},
  author = {Su, Yansen and Lin, Rongxin and Wang, Jing and Tan, Dayu and Zheng, Chunhou},
  year = {2023},
  month = mar,
  journal = {Briefings in Bioinformatics},
  volume = {24},
  number = {2},
  pages = {bbad021},
  issn = {1467-5463, 1477-4054},
  doi = {10.1093/bib/bbad021},
  abstract = {A large number of works have presented the single-cell RNA sequencing (scRNA-seq) to study the diversity and biological functions of cells at the single-cell level. Clustering identifies unknown cell types, which is essential for downstream analysis of scRNA-seq samples. However, the high dimensionality, high noise and pervasive dropout rate of scRNA-seq samples have a significant challenge to the cluster analysis of scRNA-seq samples. Herein, we propose a new adaptive fuzzy clustering model based on the denoising autoencoder and self-attention mechanism called the scDASFK. It implements the comparative learning to integrate cell similar information into the clustering method and uses a deep denoising network module to denoise the data. scDASFK consists of a self-attention mechanism for further denoising where an adaptive clustering optimization function for iterative clustering is implemented. In order to make the denoised latent features better ref lect the cell structure, we introduce a new adaptive feedback mechanism to supervise the denoising process through the clustering results. Experiments on 16 real scRNA-seq datasets show that scDASFK performs well in terms of clustering accuracy, scalability and stability. Overall, scDASFK is an effective clustering model with great potential for scRNAseq samples analysis. Our scDASFK model codes are freely available at https://github.com/LRX2022/scDASFK.},
  langid = {english}
}

@misc{thepandasdevelopmentteamPandasdevPandasPandas2023,
  title = {Pandas-Dev/Pandas: {{Pandas}}},
  shorttitle = {Pandas-Dev/Pandas},
  author = {{The pandas development team}},
  year = {2023},
  month = oct,
  doi = {10.5281/ZENODO.3509134},
  abstract = {Pandas is a powerful data structures for data analysis, time series, and statistics.},
  copyright = {BSD 3-Clause "New" or "Revised" License},
  howpublished = {Zenodo}
}

@misc{TransformersSoftwareEngineers,
  title = {Transformers for Software Engineers - {{Made}} of {{Bugs}}},
  howpublished = {https://blog.nelhage.com/post/transformers-for-software-engineers/}
}

@misc{vaswaniAttentionAllYou2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2023},
  month = aug,
  number = {arXiv:1706.03762},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.03762},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arXiv}
}

@misc{virshupAnndataAnnotatedData2021,
  title = {Anndata: {{Annotated}} Data},
  shorttitle = {Anndata},
  author = {Virshup, Isaac and Rybakov, Sergei and Theis, Fabian J. and Angerer, Philipp and Wolf, F. Alexander},
  year = {2021},
  month = dec,
  pages = {2021.12.16.473007},
  publisher = {{bioRxiv}},
  doi = {10.1101/2021.12.16.473007},
  abstract = {anndata is a Python package for handling annotated data matrices in memory and on disk (github.com/theislab/anndata), positioned between pandas and xarray. anndata offers a broad range of computationally efficient features including, among others, sparse data support, lazy operations, and a PyTorch interface. Statement of need Generating insight from high-dimensional data matrices typically works through training models that annotate observations and variables via low-dimensional representations. In exploratory data analysis, this involves iterative training and analysis using original and learned annotations and task-associated representations. anndata offers a canonical data structure for book-keeping these, which is neither addressed by pandas (McKinney, 2010), nor xarray (Hoyer \& Hamman, 2017), nor commonly-used modeling packages like scikit-learn (Pedregosa et al., 2011).},
  chapter = {New Results},
  copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}

@misc{vyasFastTransformersClustered2020,
  title = {Fast {{Transformers}} with {{Clustered Attention}}},
  author = {Vyas, Apoorv and Katharopoulos, Angelos and Fleuret, François},
  year = {2020},
  month = sep,
  number = {arXiv:2007.04825},
  eprint = {2007.04825},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2007.04825},
  abstract = {Transformers have been proven a successful model for a variety of tasks in sequence modeling. However, computing the attention matrix, which is their key component, has quadratic complexity with respect to the sequence length, thus making them prohibitively expensive for large sequences. To address this, we propose clustered attention, which instead of computing the attention for every query, groups queries into clusters and computes attention just for the centroids. To further improve this approximation, we use the computed clusters to identify the keys with the highest attention per query and compute the exact key/query dot products. This results in a model with linear complexity with respect to the sequence length for a fixed number of clusters. We evaluate our approach on two automatic speech recognition datasets and show that our model consistently outperforms vanilla transformers for a given computational budget. Finally, we demonstrate that our model can approximate arbitrarily complex attention distributions with a minimal number of clusters by approximating a pretrained BERT model on GLUE and SQuAD benchmarks with only 25 clusters and no loss in performance.},
  archiveprefix = {arXiv}
}

@article{wendtSinglecellRNAseqAtlas2020,
  title = {A Single-Cell {{RNA-seq}} Atlas of {{Schistosoma}} Mansoni Identifies a Key Regulator of Blood Feeding},
  author = {Wendt, George and Zhao, Lu and Chen, Rui and Liu, Chenxi and O'Donoghue, Anthony J. and Caffrey, Conor R. and Reese, Michael L. and Collins, James J.},
  year = {2020},
  month = sep,
  journal = {Science (New York, N.Y.)},
  volume = {369},
  number = {6511},
  pages = {1644--1649},
  issn = {1095-9203},
  doi = {10.1126/science.abb7709},
  abstract = {Schistosomiasis is a neglected tropical disease that infects 240 million people. With no vaccines and only one drug available, new therapeutic targets are needed. The causative agents, schistosomes, are intravascular flatworm parasites that feed on blood and lay eggs, resulting in pathology. The function of the parasite's various tissues in successful parasitism are poorly understood, hindering identification of therapeutic targets. Using single-cell RNA sequencing (RNA-seq), we characterize 43,642 cells from the adult schistosome and identify 68 distinct cell populations, including specialized stem cells that maintain the parasite's blood-digesting gut. These stem cells express the gene hnf4, which is required for gut maintenance, blood feeding, and pathology in vivo. Together, these data provide molecular insights into the organ systems of this important pathogen and identify potential therapeutic targets.},
  langid = {english},
  pmcid = {PMC7875187},
  pmid = {32973030}
}

@article{wolfSCANPYLargescaleSinglecell2018,
  title = {{{SCANPY}}: Large-Scale Single-Cell Gene Expression Data Analysis},
  shorttitle = {{{SCANPY}}},
  author = {Wolf, F. Alexander and Angerer, Philipp and Theis, Fabian J.},
  year = {2018},
  month = dec,
  journal = {Genome Biology},
  volume = {19},
  number = {1},
  pages = {1--5},
  publisher = {{BioMed Central}},
  issn = {1474-760X},
  doi = {10.1186/s13059-017-1382-0},
  abstract = {Scanpy is a scalable toolkit for analyzing single-cell gene expression data. It includes methods for preprocessing, visualization, clustering, pseudotime and trajectory inference, differential expression testing, and simulation of gene regulatory networks. Its Python-based implementation efficiently deals with data sets of more than one million cells ( https://github.com/theislab/Scanpy ). Along with Scanpy, we present AnnData, a generic class for handling annotated data matrices ( https://github.com/theislab/anndata ).},
  copyright = {2018 The Author(s)},
  langid = {english}
}

@article{yangScBERTLargescalePretrained2022,
  title = {{{scBERT}} as a Large-Scale Pretrained Deep Language Model for Cell Type Annotation of Single-Cell {{RNA-seq}} Data},
  author = {Yang, Fan and Wang, Wenchuan and Wang, Fang and Fang, Yuan and Tang, Duyu and Huang, Junzhou and Lu, Hui and Yao, Jianhua},
  year = {2022},
  month = oct,
  journal = {Nature Machine Intelligence},
  volume = {4},
  number = {10},
  pages = {852--866},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-022-00534-z},
  abstract = {Annotating cell types on the basis of single-cell RNA-seq data is a prerequisite for research on disease progress and tumour microenvironments. Here we show that existing annotation methods typically suffer from a lack of curated marker gene lists, improper handling of batch effects and difficulty in leveraging the latent gene–gene interaction information, impairing their generalization and robustness. We developed a pretrained deep neural network-based model, single-cell bidirectional encoder representations from transformers (scBERT), to overcome the challenges. Following BERT’s approach to pretraining and fine-tuning, scBERT attains a general understanding of gene–gene interactions by being pretrained on huge amounts of unlabelled scRNA-seq data; it is then transferred to the cell type annotation task of unseen and user-specific scRNA-seq data for supervised fine-tuning. Extensive and rigorous benchmark studies validated the superior performance of scBERT on cell type annotation, novel cell type discovery, robustness to batch effects and model interpretability.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english}
}

@article{zeiselCellTypesMouse2015,
  title = {Cell Types in the Mouse Cortex and Hippocampus Revealed by Single-Cell {{RNA-seq}}},
  author = {Zeisel, Amit and {Muñoz-Manchado}, Ana B. and Codeluppi, Simone and Lönnerberg, Peter and La Manno, Gioele and Juréus, Anna and Marques, Sueli and Munguba, Hermany and He, Liqun and Betsholtz, Christer and Rolny, Charlotte and {Castelo-Branco}, Gonçalo and {Hjerling-Leffler}, Jens and Linnarsson, Sten},
  year = {2015},
  month = mar,
  journal = {Science},
  volume = {347},
  number = {6226},
  pages = {1138--1142},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aaa1934},
  abstract = {The mammalian cerebral cortex supports cognitive functions such as sensorimotor integration, memory, and social behaviors. Normal brain function relies on a diverse set of differentiated cell types, including neurons, glia, and vasculature. Here, we have used large-scale single-cell RNA sequencing (RNA-seq) to classify cells in the mouse somatosensory cortex and hippocampal CA1 region. We found 47 molecularly distinct subclasses, comprising all known major cell types in the cortex. We identified numerous marker genes, which allowed alignment with known cell types, morphology, and location. We found a layer I interneuron expressing Pax6 and a distinct postmitotic oligodendrocyte subclass marked by Itpr2. Across the diversity of cortical cell types, transcription factors formed a complex, layered regulatory code, suggesting a mechanism for the maintenance of adult cell type identity.}
}
